{   
    "gpt-3.5-turbo": {
        "max_tokens": 100,
        "temperature": 0.01  
    },
    "gpt-3.5-turbo-1106": {
        "max_tokens": 100,
        "temperature": 0.01  
    },
    "claude-3-haiku-20240307": {
        "max_tokens": 100,
        "temperature": 0.01
    },
    "claude-3-sonnet-20240229": {
        "max_tokens": 100,
        "temperature": 0.01
    },
    "gpt-4-turbo": {
        "max_tokens": 300,
        "temperature": 0.01  
    },
    "mistral-large-latest": {
        "max_tokens": 300,
        "temperature": 0.01  
    },
    "open-mistral-nemo": {
        "max_tokens": 100,
        "temperature": 0.01  
    },
    "mistral-medium-latest": {
        "max_tokens": 100,
        "temperature": 0.01  
    },
    "gemini-1.0-pro": {
        "max_tokens": 100,
        "temperature": 0.01,
        "project": "gen-lang-client-0724822733"
    },
    "mistral-small-2402": {
        "max_tokens": 100,
        "temperature": 0.01  
    }
}
